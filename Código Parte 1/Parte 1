#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import division
import urllib
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from matplotlib import pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.lda import LDA
from sklearn.qda import QDA
from sklearn.neighbors import KNeighborsClassifier
import random


####################################################
########## Parte a: Extracción de datos ############
####################################################
# train_data_url = "http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/vowel.train"
# test_data_url = "http://statweb.stanford.edu/~tibs/ElemStatLearn/datasets/vowel.test"
# train_data_f = urllib.urlretrieve(train_data_url, "train_data.csv")
# test_data_f = urllib.urlretrieve(test_data_url, "test_data.csv")
train_df = pd.DataFrame.from_csv('train_data.csv',header=0,index_col=0)
test_df = pd.DataFrame.from_csv('test_data.csv',header=0,index_col=0)
train_df.head()
test_df.tail()

# Registros en dataframes:
print "Registros conjunto de entrenamiento: ", len(train_df.index)
print "Registros conjunto de testing: ", len(test_df.index)

len_training_set=len(train_df.index)


promedios_clase_t={}
mclasses=(1,2,3,4,5,6,7,8,9,10,11)
for classes in mclasses:
    promedios_clase_t[classes]=float(((train_df["y"]==classes).sum())/10)
    print float(((train_df["y"]==classes).sum())/10)

promedios_clase_test={}
mclasses=(1,2,3,4,5,6,7,8,9,10,11)
for classes in mclasses:
    promedios_clase_t[classes]=float(((train_df["y"]==classes).sum())/10)
    print float(((train_df["y"]==classes).sum())/10)






####################################################
########## Parte b: Preparación de datos ###########
####################################################

X = train_df.ix[:,'x.1':'x.10'].values
y = train_df.ix[:,'y'].values
X_std = StandardScaler().fit_transform(X)


Xtest = test_df.ix[:,'x.1':'x.10'].values
ytest = test_df.ix[:,'y'].values
X_std_test = StandardScaler().fit_transform(Xtest)



####################################################
########## Parte c: PCA ############################
####################################################

def parte_c_PCA():
    sklearn_pca = PCA(n_components=2)
    Xred_pca = sklearn_pca.fit_transform(X_std)
    cmap = plt.cm.get_cmap('Set1')
    mclasses=(1,2,3,4,5,6,7,8,9,10,11)
    mcolors = [cmap(i) for i in np.linspace(0,1,11)]
    plt.figure(figsize=(12, 8))
    for lab, col in zip(mclasses,mcolors):
        plt.scatter(Xred_pca[y==lab, 0],Xred_pca[y==lab, 1],label=lab,c=col)
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')
    leg = plt.legend(loc='upper right', fancybox=True)
    plt.show()



####################################################
########## Parte d: LDA ############################
####################################################

def parte_d_LDA():

    sklearn_lda = LDA(n_components=2)
    Xred_lda = sklearn_lda.fit_transform(X_std,y)
    cmap = plt.cm.get_cmap('Set1')
    mclasses=(1,2,3,4,5,6,7,8,9,10,11)
    mcolors = [cmap(i) for i in np.linspace(0,1,11)]
    plt.figure(figsize=(12, 8))
    for lab, col in zip(mclasses,mcolors):
        plt.scatter(Xred_lda[y==lab, 0],Xred_lda[y==lab, 1],label=lab,c=col)

    plt.xlabel('LDA/Fisher Direction 1')
    plt.ylabel('LDA/Fisher Direction 2')
    leg = plt.legend(loc='upper right', fancybox=True)
    plt.show()



# ####################################################
# ########## Parte f: Construcción Clasificador ######
# ####################################################

def parte_f_clasificador():
    porcentaje={}
    porcentaje[0]=0
    mclasses=(1,2,3,4,5,6,7,8,9,10,11)
    len_training_set=len(train_df.index)
    acumulative=0
    for classes in mclasses:
        acumulative = acumulative + float(((train_df["y"]==classes).sum())/len_training_set)
        porcentaje[classes]=acumulative


    random_number = random.uniform(0, 1)
    for i in range(1,12):
        if (random_number < porcentaje[i]) and (random_number > porcentaje[(i-1)]):
            return i

# ##############################################################
# ########## Parte g: Comparación desempeño LDA, QDA, K-NN #####
# ##############################################################


def parte_g_desempenio():
    ############ LDA #####################
    #Construcción y Fit del modelo LDA
    lda_model = LDA()
    lda_model.fit(X_std,y)
    #Score conjunto de entrenamiento y conjunto de testing.
    print lda_model.score(X_std,y)
    print lda_model.score(X_std_test,ytest)


    ############ QDA #####################
    #Construcción y Fit del modelo QDA
    qda_model = QDA()
    qda_model.fit(X_std,y)
    #Score conjunto de entrenamiento y conjunto de testing.
    print qda_model.score(X_std,y)
    print qda_model.score(X_std_test,ytest)

    ############ KNN #####################
    #Construcción y Fit del modelo KNN
    knn_model = KNeighborsClassifier(n_neighbors=10)
    knn_model.fit(X_std,y)
    #Score conjunto de entrenamiento y conjunto de testing.
    print knn_model.score(X_std,y)
    print knn_model.score(X_std_test,ytest)


    score_training=[]
    score_test=[]
    Lclasses=range(1,len_training_set+1)
    #Comportamiento KNN
    for mclass in Lclasses:
        knn_model = KNeighborsClassifier(n_neighbors=mclass)
        knn_model.fit(X_std,y)

        score_training.append(knn_model.score(X_std,y))
        score_test.append(knn_model.score(X_std_test,ytest))

    # plt.axis([0,11,0.45,1.03])
    plt.plot(Lclasses, score_training, label="Training")
    plt.plot(Lclasses, score_test, label="Test")
    plt.legend()
    plt.xlabel('Clases')
    plt.ylabel('Score')

    plt.show()






######################################################################
########## Parte h: Comparación desempeño con PCA: LDA, QDA, K-NN ####
######################################################################


def parte_h_desempenio_PCA():
    Lclasses=range(1,10)
    score_training_QDA=[]
    score_test_QDA=[]

    score_training_LDA=[]
    score_test_LDA=[]

    score_training_KNN=[]
    score_test_KNN=[]

    for mclass in Lclasses:
        sklearn_pca = PCA(n_components=mclass)
        X_PCA = sklearn_pca.fit_transform(X_std)
        X_PCA_test = sklearn_pca.transform(X_std_test)


        knn_model = KNeighborsClassifier(n_neighbors=10)
        knn_model.fit(X_PCA,y)
        score_training_KNN.append(knn_model.score(X_PCA,y))
        score_test_KNN.append(knn_model.score(X_PCA_test,ytest))

        qda_model = QDA()
        qda_model.fit(X_PCA,y)
        score_training_QDA.append(qda_model.score(X_PCA,y))
        score_test_QDA.append(qda_model.score(X_PCA_test,ytest))

        lda_model= LDA()
        lda_model.fit(X_PCA,y)
        score_training_LDA.append(lda_model.score(X_PCA,y))
        score_test_LDA.append(lda_model.score(X_PCA_test,ytest))








    plt.plot(Lclasses, score_training_LDA, label="Training")
    plt.plot(Lclasses, score_test_LDA, label="Test")
    plt.legend()
    plt.xlabel('Clases')
    plt.ylabel('Score')
    plt.show()


    plt.plot(Lclasses, score_training_QDA, label="Training")
    plt.plot(Lclasses, score_test_QDA, label="Test")
    plt.legend()
    plt.xlabel('Clases')
    plt.ylabel('Score')
    plt.show()

    plt.plot(Lclasses, score_training_KNN, label="Training")
    plt.plot(Lclasses, score_test_KNN, label="Test")
    plt.legend()
    plt.xlabel('Clases')
    plt.ylabel('Score')
    plt.show()









# ######################################################################
# ########## Parte i: Comparación desempeño con LDA: LDA, QDA, K-NN ####
# ######################################################################

def parte_i_desempenio_LDA():
    dimensiones = len(train_df.columns)
    dimensiones=range(1,dimensiones)

    score_training_QDA=[]
    score_test_QDA=[]

    score_training_LDA=[]
    score_test_LDA=[]

    score_training_KNN=[]
    score_test_KNN=[]

    for dimension in dimensiones:

        sklearn_lda = LDA(n_components=dimension)
        X_LDA = sklearn_lda.fit_transform(X_std,y)
        X_LDA_test = sklearn_lda.transform(X_std_test)


        knn_model = KNeighborsClassifier(n_neighbors=10)
        knn_model.fit(X_LDA,y)
        score_training_KNN.append(knn_model.score(X_LDA,y))
        score_test_KNN.append(knn_model.score(X_LDA_test,ytest))

        qda_model = QDA()
        qda_model.fit(X_LDA,y)
        score_training_QDA.append(qda_model.score(X_LDA,y))
        score_test_QDA.append(qda_model.score(X_LDA_test,ytest))

        lda_model= LDA()
        lda_model.fit(X_LDA,y)
        score_training_LDA.append(lda_model.score(X_LDA,y))
        score_test_LDA.append(lda_model.score(X_LDA_test,ytest))







    plt.plot(dimensiones, score_training_LDA, label="Training")
    plt.plot(dimensiones, score_test_LDA, label="Test")
    plt.legend()
    plt.xlabel('Clases')
    plt.ylabel('Score')
    plt.show()


    plt.plot(dimensiones, score_training_QDA, label="Training")
    plt.plot(dimensiones, score_test_QDA, label="Test")
    plt.legend()
    plt.xlabel('Clases')
    plt.ylabel('Score')
    plt.show()

    plt.plot(dimensiones, score_training_KNN, label="Training")
    plt.plot(dimensiones, score_test_KNN, label="Test")
    plt.legend()
    plt.xlabel('Clases')
    plt.ylabel('Score')
    plt.show()



parte_i_desempenio_LDA()
